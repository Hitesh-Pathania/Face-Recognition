{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AML_1204_Final term Project(Group-8)\n",
    "\n",
    "## Topic: Face Recognition\n",
    "\n",
    "### Submitted by:  \n",
    "   #### Gazal Aggarwal(C0816092)\n",
    "   #### Himanshu Hooda(C0814556)\n",
    "   #### Hitesh Pathania(C0823824)\n",
    "   #### Vikas(C0816957)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: Do not install opencv-python pacakge. Try to install opencv-contrib-python package as it include face library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection and collecting samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads the calssifier which will help us for the face detection\n",
    "face_detector = cv2.CascadeClassifier('haarcascade_frontalface_alt2.xml')\n",
    "\n",
    "# used to open video file and video capturing device\n",
    "video = cv2.VideoCapture(0)\n",
    "video.set(3, 640)  # set Width\n",
    "video.set(4, 480)  # set Height\n",
    "\n",
    "# IP address for the video stream through smartphone\n",
    "address = \"https://192.168.0.100:8080/video\"\n",
    "video.open(address)\n",
    "\n",
    "# For each person, Enter the user id => 1,2,3\n",
    "face_id = input('\\nEnter the user id: ')\n",
    "print(\"\\nInitializing camera.\")\n",
    "\n",
    "# Initialize individual sampling face count\n",
    "count = 0\n",
    "\n",
    "# initating an infinite loop that will capture video and will be later used to break the loop\n",
    "while True:\n",
    "    # ret is a boolean regarding whether or not there was a return at all, at the frame is each frame that is returned.\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # Convert image into grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # classifier function used to detect the faces, passing it some very important parameters, as scale factor, number of neighbors and minimum size of the detected face.\n",
    "    faces = face_detector.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    # making rectangle over the detected face\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "        count += 1\n",
    "\n",
    "        # before running the code make a folder name dataset in the same place as the code\n",
    "        # Save the captured image into the dataset folder\n",
    "        cv2.imwrite(\"dataset/User.\" + str(face_id) + '.' + str(count) + \".jpg\", gray[y:y + h, x:x + w])\n",
    "        cv2.imshow('image', frame)\n",
    "\n",
    "    # Wait for a key press to exit\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:  # press 'ESC' to quit\n",
    "        break\n",
    "    elif count >= 50:  # Take 50 face sample and stop video\n",
    "        break\n",
    "\n",
    "print(\"\\nSamples collected.\")\n",
    "# Close all windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for sample images\n",
    "path = 'dataset'\n",
    "\n",
    "# Local Binary Pattern Histogram for training the model\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "# face detection classifier\n",
    "detector = cv2.CascadeClassifier(\"haarcascade_frontalface_alt2.xml\");\n",
    "\n",
    "\n",
    "# function to get the images and label data\n",
    "def getImagesAndLabels(p):\n",
    "    # accesssing all files from dataset directory\n",
    "    image_Paths = [os.path.join(p, f) for f in os.listdir(p)]\n",
    "    # empty list to store array of face samples\n",
    "    face_Samples = []\n",
    "    # list to store the id of the samples\n",
    "    id_ = []\n",
    "\n",
    "    for image_Path in image_Paths:\n",
    "        # open and identifies given image from the image path convert it into grayscale\n",
    "        PIL_img = Image.open(image_Path).convert('L')\n",
    "        # converting the image into numpy array\n",
    "        img_numpy = np.array(PIL_img, 'uint8')\n",
    "        # getting the user id from the image name by splitting the image name and taking the integer part of user id\n",
    "        id = int(os.path.split(image_Path)[-1].split(\".\")[1])\n",
    "        # detecting the face\n",
    "        faces = detector.detectMultiScale(img_numpy)\n",
    "        # using for loop to print rectangle for the numpy array image and append face and id into the empty list\n",
    "        for (x, y, w, h) in faces:\n",
    "            face_Samples.append(img_numpy[y:y + h, x:x + w])\n",
    "            id_.append(id)\n",
    "    return face_Samples, id_\n",
    "\n",
    "\n",
    "print(\"\\nTraining faces. Please Wait.\")\n",
    "faces, id_ = getImagesAndLabels(path)\n",
    "# array input id_ and face_samples will be used to train the recognizer\n",
    "recognizer.train(faces, np.array(id_))\n",
    "# before running the program create a trainer folder to save the trained data\n",
    "# Save the model into trainer/trainer.yml\n",
    "recognizer.write('trainer/trainer.yml')\n",
    "# Print that the model is trained and end program\n",
    "print(\"\\nTrained. Exiting Program.\".format(len(np.unique(id_))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Binary Pattern Histogram for recognition\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "# recognizer will use the training data to recognize the face\n",
    "recognizer.read('trainer/trainer.yml')\n",
    "# face detection classifier\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt2.xml\")\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "# initiate id counter\n",
    "id = 0\n",
    "# names related to ids: example ==> Hitesh: id=1,  etc\n",
    "names = ['None', 'Hitesh', 'Harsh']\n",
    "\n",
    "# Initialize and start realtime video capture\n",
    "video = cv2.VideoCapture(0)\n",
    "video.set(3, 640)  # set video widht\n",
    "video.set(4, 480)  # set video height\n",
    "\n",
    "# Define min window size to be recognized as a face\n",
    "minW = 0.1 * video.get(3)\n",
    "minH = 0.1 * video.get(4)\n",
    "# IP address for video streaming using smartphone\n",
    "address = \"https://192.168.0.100:8080/video\"\n",
    "video.open(address)\n",
    "# infinite loop for starting the video capture device\n",
    "while True:\n",
    "    # capturing the frame of the video\n",
    "    ret, frame = video.read()\n",
    "    # converting the frame into grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # detecting the face in the video\n",
    "    faces = faceCascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5, minSize=(int(minW), int(minH)))\n",
    "    # printing a rectangle over the detected face\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        # recognizer.predict (), will take as a parameter a captured portion of the face to be analyzed\n",
    "        # will return its probable owner\n",
    "        # indicating its id and how much confidence the recognizer is in relation with this match.\n",
    "        id, confidence = recognizer.predict(gray[y:y + h, x:x + w])\n",
    "\n",
    "        # if the recognizer could predict a face, we put a text over the image with the probable id\n",
    "        # display the probability in % that the match is correct\n",
    "        # If not, an unknown label is put on the face\n",
    "        if confidence < 100:\n",
    "            id = names[id]\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "        else:\n",
    "            id = \"unknown\"\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "\n",
    "        # text for displaying the name and confidence on the frame\n",
    "        cv2.putText(frame, str(id), (x + 5, y - 5), font, 1, (255, 255, 255), 2)\n",
    "        cv2.putText(frame, str(confidence), (x + 5, y + h - 5), font, 1, (255, 255, 0), 1)\n",
    "\n",
    "    # displaying the video\n",
    "    cv2.imshow('image', frame)\n",
    "    k = cv2.waitKey(10) & 0xff  # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "print(\"\\nExiting Program.\")\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
